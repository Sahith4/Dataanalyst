<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Sahith Manchikanti's Portfolio</title>
    <link rel="stylesheet" href="styles.css">
    <link
        href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto:wght@300;500&display=swap"
        rel="stylesheet">
</head>

<body>
    <header>
        <div class="container">
            <h1>Sahith M</h1>
            <p>Data Analyst Engineer with 5 Years of Experience</p>
            <p>Contact: <a href="mailto:sahithm04@gmail.com">sahithm04@gmail.com</a> | +1 940-843-3092</p>
            <nav>
                <ul class="nav-links">
                    <li><a href="#about">About</a></li>
                    <li><a href="#education">Education</a></li>
                    <li><a href="#skills">Skills</a></li>
                    <li><a href="#experience">Experience</a></li>
                    <li><a href="#projects">Projects</a></li>
                    <li><a href="#publications">Publications</a></li>
                    <li><a href="#contact">Contact</a></li>
                </ul>
            </nav>
        </div>
    </header>

    <main>
        <section id="about">
            <div class="container">
                <h2>About Me</h2>
                <p>I am a driven computer science professional with a Master’s in Computer Science
                     and a Bachelor's in Computer Science Engineering. Skilled in data analysis, machine learning,
                      and cloud technologies, I excel in transforming complex data into actionable insights. 
                      With a strong track record in developing scalable ETL solutions and predictive models, 
                      I bring expertise in Python, Java, SQL, and diverse tech tools. My career highlights include spearheading projects at Tata Consultancy Services 
                      and contributing to academic research in computer vision and machine learning. I am committed to leveraging technology to deliver innovative solutions
                       and drive business success.</p>
            </div>
        </section>

        <section id="education" class="bg-light">
            <div class="container">
                <h2>Education</h2>
                <div class="timeline">
                    <div class="timeline-item">
                        <h3>University of North Texas (UNT), Denton, TX</h3>
                        <p>Master’s in Computer Science - May 2024</p>
                        <p>GPA: 3.7/5</p>
                    </div>
                    <div class="timeline-item">
                        <h3>Gitam University, Visakhapatnam</h3>
                        <p>Bachelor’s in Computer Science Engineering - April 2020</p>
                        <p>GPA: 7.6/10</p>
                    </div>
                </div>
            </div>
        </section>

        <section id="skills">
            <div class="container">
                <h2>Skills</h2>
                <div class="skills-grid">
                    <div class="skill-card">
                        <h3>Programming Languages</h3>
                        <p>Python, Java, Angular, JavaScript, R, Python-Flask</p>
                    </div>
                    <div class="skill-card">
                        <h3>ML Algorithms</h3>
                        <p>Decision Tree, Random Forest, KNN, SVM, Logistic/Linear Regression</p>
                    </div>
                    <div class="skill-card">
                        <h3>Querying Languages</h3>
                        <p>SQL, NoSQL, PostgreSQL</p>
                    </div>
                    <div class="skill-card">
                        <h3>Web Technologies</h3>
                        <p>HTML, CSS, AngularJS, JavaScript, Bootstrap, Node.js, GraphQL</p>
                    </div>
                    <div class="skill-card">
                        <h3>Cloud & Database Technologies</h3>
                        <p>AWS, Azure, MySQL, Redshift, Oracle, MongoDB, Snowflake, DynamoDB</p>
                    </div>
                    <div class="skill-card">
                        <h3>DevOps Tools</h3>
                        <p>Jenkins, Docker, Kubernetes</p>
                    </div>
                    <div class="skill-card">
                        <h3>Operating Systems</h3>
                        <p>Windows, Linux, Ubuntu, MacOS</p>
                    </div>
                    <div class="skill-card">
                        <h3>Data Visualization & Others</h3>
                        <p>Tableau, Power BI, Putty, GIT, SQL Developer, Jupyter, PyCharm, SAS, Matlab</p>
                    </div>
                </div>
            </div>
        </section>

        <section id="experience" class="bg-light">
            <div class="container">
                <h2>Experience</h2>
                <div class="experience-list">
                    <div class="experience-item">
                        <h3>Deutsche, USA</h3>
                        <p>Data Analyst - May 2024 to Present</p>
                        <ul>
                            <li>Spearheaded the development of reliable and scalable ETL solutions, integrating complex
                                and large volumes of data from diverse platforms and used Palantir Platform.</li>
                            <li>Demonstrated proficiency in building and maintaining data pipelines using Databricks,
                                resulting in streamlined data processing and analysis.</li>
                            <li>Transformed raw data into actionable insights using Palantir Foundry, achieving an 80%
                                success rate in client projects. Collaborated closely with clients to translate their
                                needs into data-driven solutions.</li>
                            <li>Utilized my analytical skills to uncover valuable patterns and trends within datasets.
                                Built predictive models and translated findings into clear, interactive dashboards for
                                effective communication.</li>
                            <li>Automated data pipelines and workflows to streamline operations and enhance
                                productivity. Effectively implemented data-driven insights to improve overall
                                performance.</li>
                            <li>Applied experience with various AWS cloud services, including IAM, EC2, RDS, MSK, and
                                Lambda.</li>
                            <li>Led the implementation of Apache Airflow for application orchestration, improving
                                workflow efficiency.</li>
                            <li>Utilized Python for developing custom solutions, enhancing system performance and
                                reliability.</li>
                            <li>Played a key role in the successful migration of applications, ensuring minimal downtime
                                and maximum data integrity.</li>
                            <li>Provided expert support during SIT and UAT, resolving issues promptly to meet project
                                timelines.</li>
                            <li>Proficient in using Informatica PowerCenter for ETL workflows, transformations, and data
                                integration tasks.</li>
                            <li>Contributed to the design and implementation of scalable and resilient cloud solutions
                                leveraging AWS resources.</li>
                            <li>Designed and implemented complex queries and analytics workflows in BigQuery.</li>
                            <li>Leveraged a wide range of Amazon Web Services (AWS) tools, such as EC2, S3, Cloud Front,
                                DynamoDB, Lambda, Elastic File System, RDS.</li>
                            <li>Designed, deployed, and managed infrastructure on GCP to ensure high availability,
                                security, and performance of applications.</li>
                        </ul>

                    </div>
                    <div class="experience-item">
                        <h3>Stellantis, Bangalore, India</h3>
                        <p>Data Analyst - April 2021 to August 2022</p>
                        <ul>
                            <li>Spearheaded the development of reliable and scalable ETL solutions, integrating complex
                                and large volumes of data from diverse platforms and used Palantir Platform.</li>
                            <li>Demonstrated proficiency in building and maintaining data pipelines using Databricks,
                                resulting in streamlined data processing and analysis.</li>
                            <li>Transformed raw data into actionable insights using Palantir Foundry, achieving an 80%
                                success rate in client projects. Collaborated closely with clients to translate their
                                needs into data-driven solutions.</li>
                            <li>Utilized my analytical skills to uncover valuable patterns and trends within datasets.
                                Built predictive models and translated findings into clear, interactive dashboards for
                                effective communication.</li>
                            <li>Automated data pipelines and workflows to streamline operations and enhance
                                productivity. Effectively implemented data-driven insights to improve overall
                                performance.</li>
                            <li>Applied experience with various AWS cloud services, including IAM, EC2, RDS, MSK, and
                                Lambda.</li>
                            <li>Led the implementation of Apache Airflow for application orchestration, improving
                                workflow efficiency.</li>
                            <li>Utilized Python for developing custom solutions, enhancing system performance and
                                reliability.</li>
                            <li>Played a key role in the successful migration of applications, ensuring minimal downtime
                                and maximum data integrity.</li>
                            <li>Provided expert support during SIT and UAT, resolving issues promptly to meet project
                                timelines.</li>
                            <li>Proficient in using Informatica PowerCenter for ETL workflows, transformations, and data
                                integration tasks.</li>
                            <li>Contributed to the design and implementation of scalable and resilient cloud solutions
                                leveraging AWS resources.</li>
                            <li>Designed and implemented complex queries and analytics workflows in BigQuery.</li>
                            <li>Leveraged a wide range of Amazon Web Services (AWS) tools, such as EC2, S3, Cloud Front,
                                DynamoDB, Lambda, Elastic File System, RDS.</li>
                            <li>Designed, deployed, and managed infrastructure on GCP to ensure high availability,
                                security, and performance of applications.</li>
                        </ul>

                    </div>
                    <div class="experience-item">
                        <h3>Tech Mahindra, Bangalore, India</h3>
                        <p>Data Analyst - January 2021 to March 2021</p>
                        <ul>
                            <li>Experienced Python developer skilled in using Beautiful Soup and Scrapy to extract data
                                from websites.</li>
                            <li>Analyzed datasets using advanced models to uncover patterns and trends beneficial for
                                business decisions.</li>
                            <li>Skilled in web scraping and data analysis with Python, transforming raw data into
                                actionable insights for businesses.</li>
                            <li>Conducted data analysis on weblog data using HiveQL and integrated Oozie with the Hadoop
                                stack to support various Hadoop jobs such as MapReduce, Pig, Hive, and Sqoop, as well as
                                system-specific jobs like Java programs and shell scripts.</li>
                            <li>Transferred and transformed purchase transaction details from legacy systems to HDFS
                                using Java MapReduce programs.</li>
                            <li>Developed custom PIG UDFs and Loaders to manipulate and transform data as per business
                                requirements, and performed ETL data cleansing, integration, and transformation using
                                Pig.</li>
                        </ul>

                    </div>
                    <div class="experience-item">
                        <h3>LN Technical Services, Hyderabad, India</h3>
                        <p>Data Engineer - November 2018 to December 2021</p>
                        <ul>
                            <li>Demonstrated proficiency in data manipulation leveraging JavaScript, TypeScript, and
                                Python, adapting seamlessly to diverse projects.</li>
                            <li>Leveraged Databricks clusters to enhance data transformation and aggregation for
                                analytical purposes, improving data-driven decision-making.</li>
                            <li>Oversaw data warehousing within Azure Synapse Analytics, managing data models, schemas,
                                and tables to support reporting and analytical needs effectively.</li>
                            <li>Utilized AWS Glue, Python scripts, and Apache Spark to create efficient data processing
                                workflows and automate data ingestion from various sources into S3 and data lakes.</li>
                            <li>Maintained version control for DBT projects using Git, enabling collaboration and
                                tracking changes.</li>
                            <li>Implemented a scalable data storage solution using the Iceberg framework.</li>
                            <li>Designed and implemented ETL processes to efficiently load, transform, and manage large
                                datasets in the Amazon Redshift environment.</li>
                            <li>Orchestrated complex data workflows and ETL processes using Azure Data Factory (ADF) to
                                ensure seamless data movement and transformation.</li>
                            <li>Designed and implemented data pipelines in ADF, leveraging its features to extract,
                                transform, and load data from various sources into destination systems.</li>
                            <li>Integrated Unix Shell scripts with database systems using PL/SQL for seamless data
                                extraction and manipulation.</li>
                            <li>Collaborated with the team to integrate Iceberg seamlessly into existing project
                                architecture.</li>
                            <li>Worked as a subject matter expert in technical reviews and provided guidance on the
                                implementation of data architectures, including Star and Snowflake schemas.</li>
                            <li>Developed and maintained large-scale data processing pipelines using PySpark, Spark SQL,
                                and Spark Streaming for real-time data processing and analytics.</li>
                            <li>Designed and built data marts for efficient data access and reporting, employing Star
                                Schema and Snowflake Schema methodologies.</li>
                            <li>Staying up-to-date with the latest developments in GCP and cloud technology to recommend
                                innovative solutions and improvements.</li>
                            <li>Provided technical expertise in data integration, data mapping, and data profiling using
                                SQL and ETL processes.</li>
                            <li>Developed web-based applications using Python, CSS, and HTML to provide data
                                visualization and reporting capabilities.</li>
                            <li>Utilized advanced object-oriented and object function scripting languages, demonstrating
                                versatility and efficiency in coding practices.</li>
                            <li>Collaborated with reporting developers to ensure successful implementation of
                                report/universe designs for business intelligence needs.</li>
                            <li>Implemented continuous project build and deployment processes using Subversion, Git,
                                Jenkins, IIS, and Tomcat.</li>
                            <li>Utilized Tableau to analyze and interpret business data, providing key insights for
                                decision-making.</li>
                            <li>Utilized S3 bucket and Glacier for storage and backup of critical data on AWS.</li>
                        </ul>
                    </div>
                </div>
            </div>
        </section>

        <section id="projects">
            <div class="container">
                <h2>Projects</h2>
                <div class="projects-grid">
                    <div class="project-card">
                        <h3>University Admission Prediction</h3>
                        <p>Developed a Python-based predictive model for university admission decisions with 79%
                            accuracy.</p>
                    </div>
                    <div class="project-card">
                        <h3>Online Web Scraping and Data Extraction on Amazon</h3>
                        <p>Automated web scraping for Amazon using Python, transforming raw data into actionable
                            insights.</p>
                    </div>
                    <div class="project-card">
                        <h3>Restaurant Management Systems</h3>
                        <p>Designed and implemented a database system for restaurant management using Java and MySQL.
                        </p>
                    </div>
                </div>
            </div>
        </section>

        <section id="publications" class="bg-light">
            <div class="container">
                <h2>Publications</h2>
                <p><strong>Object Detection System using Image Processing, Machine Learning, and Python</strong></p>
                <p>Published in the Journal of Xi'an University of Architecture & Technology, April 2020.</p>
                <p>This system is used for monitoring and communication in various applications, including army base
                    regulation and underwater rescue missions.</p>
            </div>
        </section>

        <section id="contact">
            <div class="container">
                <h2>Contact</h2>
                <p>Email: <a href="mailto:sahithm04@gmail.com">sahithm04@gmail.com</a></p>
                <p>Phone: +1 940-843-3092</p>
            </div>
        </section>
    </main>

    <footer>
        <div class="container">
            <p>&copy; 2024 Sahith M. All rights reserved.</p>
        </div>
    </footer>

    <script src="script.js"></script>
</body>

</html>
